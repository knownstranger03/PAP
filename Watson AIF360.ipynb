{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# <font color='red'>Question 1</font>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# <font color='green'>Working with AIF360 on IBM Watson\n    \n    - Bias and Fairness analysis on loan defaulters prediction", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#Firstly install Aif360 package -> Uncomment the below line\n!pip install aif360\n!pip install cvxpy==0.4.11", 
            "cell_type": "code", 
            "execution_count": 1, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting aif360\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/5d/da04c68bd82f2d358146aafc18aed02326ab772a135660af499b6f73bb09/aif360-0.2.1-py2.py3-none-any.whl (56.4MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 56.4MB 55.1MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aif360) (1.2.0)\nRequirement already satisfied: pandas>=0.23.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aif360) (0.24.1)\nCollecting numpy>=1.16 (from aif360)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/b9/bda9781f0a74b90ebd2e046fde1196182900bd4a8e1ea503d3ffebc50e7c/numpy-1.17.0-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20.4MB 37.0MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aif360) (0.20.3)\nRequirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas>=0.23.3->aif360) (2.7.5)\nRequirement already satisfied: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas>=0.23.3->aif360) (2018.9)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.23.3->aif360) (1.12.0)\n\u001b[31mERROR: tensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\nInstalling collected packages: numpy, aif360\n  Found existing installation: numpy 1.15.4\n    Uninstalling numpy-1.15.4:\n      Successfully uninstalled numpy-1.15.4\nSuccessfully installed aif360-0.2.1 numpy-1.17.0\nCollecting cvxpy==0.4.11\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/52/d2928100c93e726acdbb793e4a3662d4c65ace58ca0ddd09463a172f7bed/cvxpy-0.4.11.tar.gz (159kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 163kB 16.3MB/s eta 0:00:01\n\u001b[?25hCollecting ecos>=2 (from cvxpy==0.4.11)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ed/d131ff51f3a8f73420eb1191345eb49f269f23cadef515172e356018cde3/ecos-2.0.7.post1-cp36-cp36m-manylinux1_x86_64.whl (147kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153kB 22.5MB/s eta 0:00:01\n\u001b[?25hCollecting scs>=1.1.3 (from cvxpy==0.4.11)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/6e/dbdd778c64c1920ae357a2013ea655d65a1f8b60f397d6e5549e4aafe8ec/scs-2.1.1-2.tar.gz (157kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 163kB 30.1MB/s eta 0:00:01\n\u001b[?25hCollecting multiprocess (from cvxpy==0.4.11)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/40/b23b1ddd3cb0e072fdbec5f458e8369df48643a3b04dfb55365a63a51687/multiprocess-0.70.8.tar.gz (1.6MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.6MB 30.0MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: fastcache in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (1.0.2)\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (1.12.0)\nRequirement already satisfied: toolz in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (0.9.0)\nRequirement already satisfied: numpy>=1.9 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (1.17.0)\nRequirement already satisfied: scipy>=0.15 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (1.2.0)\nCollecting CVXcanon>=0.0.22 (from cvxpy==0.4.11)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/e6/63eb6e7dca5dcb723429e65b456d0e3638976e63f6696b7eb48fee3a491d/CVXcanon-0.1.1.tar.gz (694kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 696kB 44.2MB/s eta 0:00:01\n\u001b[?25hCollecting dill>=0.3.0 (from multiprocess->cvxpy==0.4.11)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/7a/70803635c850e351257029089d38748516a280864c97cbc73087afef6d51/dill-0.3.0.tar.gz (151kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153kB 46.4MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: cvxpy, scs, multiprocess, CVXcanon, dill\n  Building wheel for cvxpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/2d/26/ba/f0a0388a7ab98124caf88ea8b532b81cf4acb1b6a4a990e3b4\n  Building wheel for scs (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/68/3f/24/e9c75d426f600634cdac68321184ba06fdc4ab2d189b5c4541\n  Building wheel for multiprocess (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/b9/61/60/f2130887941f13dcbbfbc4ceef5f1114ea1ea3ff372444965c\n  Building wheel for CVXcanon (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/46/a7/aa/2116e25ce5ef04deae6a3c4d01908449e572393351edf65b14\n  Building wheel for dill (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/c9/de/a4/a91eec4eea652104d8c81b633f32ead5eb57d1b294eab24167\nSuccessfully built cvxpy scs multiprocess CVXcanon dill\nInstalling collected packages: ecos, scs, dill, multiprocess, CVXcanon, cvxpy\n  Found existing installation: dill 0.2.8.2\n    Uninstalling dill-0.2.8.2:\n      Successfully uninstalled dill-0.2.8.2\nSuccessfully installed CVXcanon-0.1.1 cvxpy-0.4.11 dill-0.3.0 ecos-2.0.7.post1 multiprocess-0.70.8 scs-2.1.1.post2\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# Load all necessary packages\n\nimport sys\nsys.path.insert(1, \"../\")  #this will append a new location to accept environment variables from\n\nimport os\n\nimport numpy as np\nnp.random.seed(0)\n\nfrom aif360.datasets import GermanDataset #Data set\n\nfrom aif360.metrics import BinaryLabelDatasetMetric\nfrom aif360.algorithms.preprocessing import Reweighing\n\nfrom IPython.display import Markdown, display", 
            "cell_type": "code", 
            "execution_count": 2, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "#Adding a location to read data from\n\naif360_location = !python -c \"from distutils.sysconfig import get_python_lib; print(get_python_lib())\"\n\ninstall_loc = os.path.join(aif360_location[0], \"aif360/data/raw/german/\")\n\n#Checking the current directory\n%cd $install_loc", 
            "cell_type": "code", 
            "execution_count": 3, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/aif360/data/raw/german\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "#Loading the actual dataset to local location from module ftp\n!wget ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.data\n!wget ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.doc", 
            "cell_type": "code", 
            "execution_count": 4, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2019-08-21 11:12:26--  ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.data\n           => \u2018german.data.1\u2019\nResolving ftp.ics.uci.edu (ftp.ics.uci.edu)... 128.195.1.14\nConnecting to ftp.ics.uci.edu (ftp.ics.uci.edu)|128.195.1.14|:21... connected.\nLogging in as anonymous ... Logged in!\n==> SYST ... done.    ==> PWD ... done.\n==> TYPE I ... done.  ==> CWD (1) /pub/machine-learning-databases/statlog/german ... done.\n==> SIZE german.data ... 79793\n==> PASV ... done.    ==> RETR german.data ... done.\nLength: 79793 (78K) (unauthoritative)\n\n100%[======================================>] 79,793      --.-K/s   in 0.07s   \n\n2019-08-21 11:12:27 (1.02 MB/s) - \u2018german.data.1\u2019 saved [79793]\n\n--2019-08-21 11:12:28--  ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.doc\n           => \u2018german.doc.1\u2019\nResolving ftp.ics.uci.edu (ftp.ics.uci.edu)... 128.195.1.14\nConnecting to ftp.ics.uci.edu (ftp.ics.uci.edu)|128.195.1.14|:21... connected.\nLogging in as anonymous ... Logged in!\n==> SYST ... done.    ==> PWD ... done.\n==> TYPE I ... done.  ==> CWD (1) /pub/machine-learning-databases/statlog/german ... done.\n==> SIZE german.doc ... 4679\n==> PASV ... done.    ==> RETR german.doc ... done.\nLength: 4679 (4.6K) (unauthoritative)\n\n100%[======================================>] 4,679       --.-K/s   in 0.003s  \n\n2019-08-21 11:12:29 (1.58 MB/s) - \u2018german.doc.1\u2019 saved [4679]\n\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "%cd -\ndataset_orig = GermanDataset(protected_attribute_names=['age'],\n# this dataset also contains protected\n# attribute for \"sex\" which we do not\n# consider in this evaluation\nprivileged_classes=[lambda x: x >= 25],      # age >=25 is considered privileged\nfeatures_to_drop=['personal_status', 'sex']) # ignore sex-related attributes\n\ndataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n\nprivileged_groups = [{'age': 1}]\nunprivileged_groups = [{'age': 0}]", 
            "cell_type": "code", 
            "execution_count": 5, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/home/dsxuser/work\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n                                             unprivileged_groups=unprivileged_groups,\n                                             privileged_groups=privileged_groups)\ndisplay(Markdown(\"#### Original training dataset\"))\nprint(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())", 
            "cell_type": "code", 
            "execution_count": 6, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/markdown": "#### Original training dataset", 
                        "text/plain": "<IPython.core.display.Markdown object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Difference in mean outcomes between unprivileged and privileged groups = -0.169905\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n                privileged_groups=privileged_groups)\ndataset_transf_train = RW.fit_transform(dataset_orig_train)", 
            "cell_type": "code", 
            "execution_count": 7, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n                                               unprivileged_groups=unprivileged_groups,\n                                               privileged_groups=privileged_groups)\ndisplay(Markdown(\"#### Transformed training dataset\"))\nprint(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())", 
            "cell_type": "code", 
            "execution_count": 8, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/markdown": "#### Transformed training dataset", 
                        "text/plain": "<IPython.core.display.Markdown object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "file=open(\"fairness.txt\", 'a+')\nfile.write(\"Bias = 0.0\")\nfile.close", 
            "cell_type": "code", 
            "execution_count": 9, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<function TextIOWrapper.close()>"
                    }, 
                    "execution_count": 9
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# <font color='green'>Summary</font>\n\n- The average difference between privilidged and under privileged groups is 0, this basically means there is no bias given the selection of our metric.\n- There can be several metrics to check bias and fairness of a machine learning model based on the domain of work\n- It is recommended to always check as many times as possible for bias in the model and constantly work to correecting it, in order to create the best model for realtime usage.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# <font color='red'>Question 2</font>\n# Keras exercise\n- Creating a Keras model by loading an inbuilt data set\n- preprocessing input data\n- building a Sequential Keras model and compiling the model with a training configuration\n- model evaluation\n\n# Goal\n- Create a Multi-layer perceptron (MLP) using Keras which is trained to classify news items into the specified 46 topics.\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#Installing Keras if not installed already\ntry:\n    __import__('keras')\nexcept ImportError:\n    pip.main(['install', 'keras']) \n    \n    \n#Importing required functions\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.utils import to_categorical", 
            "cell_type": "code", 
            "execution_count": 10, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# Data\n- Reuters newswire dataset.\n         *This dataset consists of 11,228 newswires from the Reuters news agency. Each wire is encoded as a sequence of word indexes. Moreover, each wire is categorised into one of 46 topics, which will serve as our label. This dataset is available through the Keras API.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#This step is to change the default loading parameters of Numpy module\nnp_load_old = np.load\n\n# modify the default parameters of np.load\nnp.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)", 
            "cell_type": "code", 
            "execution_count": 11, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "from keras.datasets import reuters #importing the dataset\n\n#Train test validation split in 80/20 ratio\nmax_words = 1000\n(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n                                                         test_split=0.2,\n                                                         seed=1344)\nnum_classes = np.max(y_train) + 1 #number of categories will be the max_val of y_train+1 because the indexing would've started from 0", 
            "cell_type": "code", 
            "execution_count": 12, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n2113536/2110848 [==============================] - 0s 0us/step\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# restore np.load to its default parameters\nnp.load = np_load_old", 
            "cell_type": "code", 
            "execution_count": 13, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "#tokenizing words is to split each word separately, whihc gives us each instance in the data as a separate attribute\n\nfrom keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=max_words)\nx_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\nx_test = tokenizer.sequences_to_matrix(x_test, mode='binary')", 
            "cell_type": "code", 
            "execution_count": 14, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "y_train = to_categorical(y_train, num_classes=num_classes) #changing the taget variable to categories\ny_test = to_categorical(y_test, num_classes=num_classes)", 
            "cell_type": "code", 
            "execution_count": 15, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "#defining a ANN model\n\nmodel = Sequential()  # Instantiate sequential model\n\nmodel.add(Dense(512, activation='relu', input_shape = (max_words,))) # Add first layer. Make sure to specify input shape\n\nmodel.add(Dropout(0.5)) # Add second layer with dropout\n\nmodel.add(Dense(num_classes, activation='softmax')) # Add third layer with softmax because there are more than 2 classes", 
            "cell_type": "code", 
            "execution_count": 16, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "#compiling the model with optimizer, loss and mrelevant metrics\nmodel.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])", 
            "cell_type": "code", 
            "execution_count": 17, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "#Fitting the model with dezired parameters\n\nbatch_size = 32\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=5, validation_data=(x_test,y_test))\nscore = model.evaluate(x_test,y_test, verbose=1)", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 8982 samples, validate on 2246 samples\nEpoch 1/5\n 192/8982 [..............................] - ETA: 1:24 - loss: 3.5677 - acc: 0.1875 "
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.348934). Check your callbacks.\n  % delta_t_median)\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "8982/8982 [==============================] - 24s 3ms/step - loss: 1.4054 - acc: 0.6860 - val_loss: 0.9260 - val_acc: 0.7934\nEpoch 2/5\n8982/8982 [==============================] - 23s 3ms/step - loss: 0.7913 - acc: 0.8126 - val_loss: 0.7585 - val_acc: 0.8281\nEpoch 3/5\n1216/8982 [===>..........................] - ETA: 22s - loss: 0.5156 - acc: 0.8849"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "print(\"Loss: \",score[0],\"\\nAccuracy:\",score[1])  #From the above extracting only the final and best response during 5th epoch", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "file=open(\"loss_acc.txt\", 'a+')\nfile.write(\"Loss = 73.72 + \\n +Accuracy= 82.01\")\nfile.close", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# <font color='green'>Summary\n\n- The MLP model created using Keras API on Watson has successfully classified the newswires into the designated 48 categories with 82.01 accuracy.", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }
}