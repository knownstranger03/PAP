{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# <font color='red'>Question 1</font>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# <font color='green'>Working with AIF360 on IBM Watson\n    \n    - Bias and Fairness analysis on loan defaulters prediction", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#Firstly install Aif360 package -> Uncomment the below line\n# !pip install aif360\n# !pip install cvxpy==0.4.11", 
            "cell_type": "code", 
            "execution_count": 1, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Requirement already satisfied: aif360 in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.2.1)\nRequirement already satisfied: scipy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aif360) (1.2.0)\nRequirement already satisfied: pandas>=0.23.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aif360) (0.24.1)\nRequirement already satisfied: scikit-learn in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aif360) (0.20.3)\nRequirement already satisfied: numpy>=1.16 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aif360) (1.17.0)\nRequirement already satisfied: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas>=0.23.3->aif360) (2018.9)\nRequirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas>=0.23.3->aif360) (2.7.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.23.3->aif360) (1.12.0)\nRequirement already satisfied: cvxpy==0.4.11 in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.4.11)\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (1.12.0)\nRequirement already satisfied: scs>=1.1.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (2.1.1.post2)\nRequirement already satisfied: scipy>=0.15 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (1.2.0)\nRequirement already satisfied: toolz in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (0.9.0)\nRequirement already satisfied: fastcache in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (1.0.2)\nRequirement already satisfied: ecos>=2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (2.0.7.post1)\nRequirement already satisfied: multiprocess in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (0.70.8)\nRequirement already satisfied: numpy>=1.9 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (1.17.0)\nRequirement already satisfied: CVXcanon>=0.0.22 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy==0.4.11) (0.1.1)\nRequirement already satisfied: dill>=0.3.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from multiprocess->cvxpy==0.4.11) (0.3.0)\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# Load all necessary packages\n\nimport sys\nsys.path.insert(1, \"../\")  #this will append a new location to accept environment variables from\n\nimport os\n\nimport numpy as np\nnp.random.seed(0)\n\nfrom aif360.datasets import GermanDataset #Data set\n\nfrom aif360.metrics import BinaryLabelDatasetMetric\nfrom aif360.algorithms.preprocessing import Reweighing\n\nfrom IPython.display import Markdown, display", 
            "cell_type": "code", 
            "execution_count": 2, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "#Adding a location to read data from\n\naif360_location = !python -c \"from distutils.sysconfig import get_python_lib; print(get_python_lib())\"\n\ninstall_loc = os.path.join(aif360_location[0], \"aif360/data/raw/german/\")\n\n#Checking the current directory\n%cd $install_loc", 
            "cell_type": "code", 
            "execution_count": 3, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/aif360/data/raw/german\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "#Loading the actual dataset to local location from module ftp\n!wget ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.data\n!wget ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.doc", 
            "cell_type": "code", 
            "execution_count": 4, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2019-08-20 12:15:09--  ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.data\n           => \u2018german.data.2\u2019\nResolving ftp.ics.uci.edu (ftp.ics.uci.edu)... 128.195.1.14\nConnecting to ftp.ics.uci.edu (ftp.ics.uci.edu)|128.195.1.14|:21... connected.\nLogging in as anonymous ... Logged in!\n==> SYST ... done.    ==> PWD ... done.\n==> TYPE I ... done.  ==> CWD (1) /pub/machine-learning-databases/statlog/german ... done.\n==> SIZE german.data ... 79793\n==> PASV ... done.    ==> RETR german.data ... done.\nLength: 79793 (78K) (unauthoritative)\n\n100%[======================================>] 79,793      --.-K/s   in 0.07s   \n\n2019-08-20 12:15:10 (1.06 MB/s) - \u2018german.data.2\u2019 saved [79793]\n\n--2019-08-20 12:15:11--  ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.doc\n           => \u2018german.doc.2\u2019\nResolving ftp.ics.uci.edu (ftp.ics.uci.edu)... 128.195.1.14\nConnecting to ftp.ics.uci.edu (ftp.ics.uci.edu)|128.195.1.14|:21... connected.\nLogging in as anonymous ... Logged in!\n==> SYST ... done.    ==> PWD ... done.\n==> TYPE I ... done.  ==> CWD (1) /pub/machine-learning-databases/statlog/german ... done.\n==> SIZE german.doc ... 4679\n==> PASV ... done.    ==> RETR german.doc ... done.\nLength: 4679 (4.6K) (unauthoritative)\n\n100%[======================================>] 4,679       --.-K/s   in 0.01s   \n\n2019-08-20 12:15:11 (344 KB/s) - \u2018german.doc.2\u2019 saved [4679]\n\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "%cd -\ndataset_orig = GermanDataset(protected_attribute_names=['age'],\n# this dataset also contains protected\n# attribute for \"sex\" which we do not\n# consider in this evaluation\nprivileged_classes=[lambda x: x >= 25],      # age >=25 is considered privileged\nfeatures_to_drop=['personal_status', 'sex']) # ignore sex-related attributes\n\ndataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n\nprivileged_groups = [{'age': 1}]\nunprivileged_groups = [{'age': 0}]", 
            "cell_type": "code", 
            "execution_count": 5, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/home/dsxuser/work\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n                                             unprivileged_groups=unprivileged_groups,\n                                             privileged_groups=privileged_groups)\ndisplay(Markdown(\"#### Original training dataset\"))\nprint(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())", 
            "cell_type": "code", 
            "execution_count": 6, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/markdown": "#### Original training dataset", 
                        "text/plain": "<IPython.core.display.Markdown object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Difference in mean outcomes between unprivileged and privileged groups = -0.169905\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n                privileged_groups=privileged_groups)\ndataset_transf_train = RW.fit_transform(dataset_orig_train)", 
            "cell_type": "code", 
            "execution_count": 7, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n                                               unprivileged_groups=unprivileged_groups,\n                                               privileged_groups=privileged_groups)\ndisplay(Markdown(\"#### Transformed training dataset\"))\nprint(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())", 
            "cell_type": "code", 
            "execution_count": 8, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/markdown": "#### Transformed training dataset", 
                        "text/plain": "<IPython.core.display.Markdown object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "<font color='green'>Summary</font>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# <font color='red'>Question 2</font>\n# Keras exercise\n- Creating a Keras model by loading an inbuilt data set\n- preprocessing input data\n- building a Sequential Keras model and compiling the model with a training configuration\n- model evaluation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "try:\n    __import__('keras')\nexcept ImportError:\n    pip.main(['install', 'keras']) \n    \n\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.utils import to_categorical", 
            "cell_type": "code", 
            "execution_count": 36, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# Data\n- Reuters newswire dataset.\n         *This dataset consists of 11,228 newswires from the Reuters news agency. Each wire is encoded as a sequence of word indexes. Moreover, each wire is categorised into one of 46 topics, which will serve as our label. This dataset is available through the Keras API.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "np_load_old = np.load\n\n# modify the default parameters of np.load\nnp.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n\nseed = 1337\nnp.random.seed(seed)", 
            "cell_type": "code", 
            "execution_count": 37, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "from keras.datasets import reuters\n\nmax_words = 1000\n(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n                                                         test_split=0.2,\n                                                         seed=seed)\nnum_classes = np.max(y_train) + 1 ", 
            "cell_type": "code", 
            "execution_count": 38, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# restore np.load for future normal usage\nnp.load = np_load_old", 
            "cell_type": "code", 
            "execution_count": 39, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=max_words)\nx_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\nx_test = tokenizer.sequences_to_matrix(x_test, mode='binary')", 
            "cell_type": "code", 
            "execution_count": 40, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "y_train = to_categorical(y_train, num_classes=num_classes)\ny_test = to_categorical(y_test, num_classes=num_classes)", 
            "cell_type": "code", 
            "execution_count": 41, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "model = Sequential()  # Instantiate sequential model\nmodel.add(Dense(512, activation='relu', input_shape = (max_words,))) # Add first layer. Make sure to specify input shape\nmodel.add(Dropout(0.5)) # Add second layer\nmodel.add(Dense(num_classes, activation='softmax')) # Add third layer", 
            "cell_type": "code", 
            "execution_count": 42, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])", 
            "cell_type": "code", 
            "execution_count": 43, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "from keras import backend as K\n\nK.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)))", 
            "cell_type": "code", 
            "execution_count": 44, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "batch_size = 32\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=5, validation_data=(x_test,y_test))\nscore = model.evaluate(x_test,y_test, verbose=1)", 
            "cell_type": "code", 
            "execution_count": 45, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 8982 samples, validate on 2246 samples\nEpoch 1/5\n8982/8982 [==============================] - 9s 1ms/step - loss: 1.3969 - acc: 0.6885 - val_loss: 0.9784 - val_acc: 0.7765\nEpoch 2/5\n8982/8982 [==============================] - 9s 975us/step - loss: 0.7714 - acc: 0.8192 - val_loss: 0.8214 - val_acc: 0.8090\nEpoch 3/5\n8982/8982 [==============================] - 9s 947us/step - loss: 0.5568 - acc: 0.8652 - val_loss: 0.8174 - val_acc: 0.8099\nEpoch 4/5\n8982/8982 [==============================] - 9s 957us/step - loss: 0.4190 - acc: 0.8926 - val_loss: 0.8370 - val_acc: 0.8010\nEpoch 5/5\n8982/8982 [==============================] - 9s 1ms/step - loss: 0.3466 - acc: 0.9107 - val_loss: 0.8556 - val_acc: 0.7988\n2246/2246 [==============================] - 1s 275us/step\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "print(\"Loss: \",score[0],\"\\nAccuracy:\",score[1])", 
            "cell_type": "code", 
            "execution_count": 46, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Loss:  0.8556284526046216 \nAccuracy: 0.798753339269813\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }
}